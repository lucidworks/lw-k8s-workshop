== Lab 4: Monitoring Query Performance

In this lab, you'll load a dataset from Google Cloud Storage and then run a query load test using Gatling.
You'll learn how to monitor query performance using Grafana dashboards.

=== Step 1: Login to Grafana and Import Dashboards

You can expose Grafana to the internet using:
```
kubectl expose deployment ${LW_K8S_RELEASE}-graf-grafana --type=LoadBalancer --name=grafana
```
This creates a new `LoadBalancer` service named `grafana` with an external IP.

How do you get the external IP for the Grafana service?
```
kubectl get service grafana -o jsonpath='{.status.loadBalancer.ingress[0].ip}'
```

Browse to Grafana on port 3000:
```
grafana_ip=$(kubectl get service grafana -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
open "http://${grafana_ip}:3000"
```

Get the initial Grafana password for `admin` from a secret:
```
kubectl get secret --namespace "${LW_K8S_NAMESPACE}" ${LW_K8S_RELEASE}-graf-grafana \
  -o jsonpath="{.data.admin-password}" | base64 --decode ; echo
```

After logging in, add a Prometheus data source with URL: `http://<RELEASE>-prom-prometheus-server` where `<RELEASE>` is the namespace for your Fusion 5 cluster.

Import one or more Grafana dashboards from the fusion-cloud-native repo: https://github.com/lucidworks/fusion-cloud-native/tree/master/monitoring/grafana

For this lab, please ensure you import the `dashboard_query_pipeline.json` and `dashboard_indexing_metrics.json` dashboards for observing query and index pipeline performance metrics.

=== Step 2: Add the Load PBL Job and Run It

Create a `lab4` app using the Fusion Admin UI.

Download: https://raw.githubusercontent.com/lucidworks/lw-k8s-workshop/master/lab4/load_data_from_gcs_pbl.json

```
curl -O https://raw.githubusercontent.com/lucidworks/lw-k8s-workshop/master/lab4/load_data_from_gcs_pbl.json
```

Download: https://raw.githubusercontent.com/lucidworks/lw-k8s-workshop/master/lab4/post_job.sh

```
curl -O https://raw.githubusercontent.com/lucidworks/lw-k8s-workshop/master/lab4/post_job.sh
```

Run `sh ./post_job.sh` from the `lab4` directory to create a PBL job for indexing data from GCS and run it from the Admin UI.

While the job is running, observe the Spark job related pods running in your cluster.

```
k get pods -l jobConfigId=lab4_load_from_GCS -o wide --watch
```

Notice how we're using the Spark Job Config ID `lab4_load_from_GCS` as pod label filter.

While the job is running, open a port-forward to the driver pod port 4040 and navigate to `http://localhost:4040` to view the Spark Job UI.

Ctrl-C once you see the driver pod is `Completed`

Observe which nodes the Spark driver and executor are running on `spark-std-8` ... why is this happening?

=== Step 3: Configure warming queries

Add the following warming queries configuration to your custom values yaml and deploy the change.
```
query-pipeline:
  warmingQueryJson:
    {
      "pipelines": [
        { "pipeline": "lab4", "collection": "lab4", "params": {"q": ["*:*"] } },
        { "pipeline": "lab4", "collection": "lab4", "params": {"q": ["string2_s:cariole^98 text1_txt_en:chemis^57"] } }
      ],
      "profiles": [
        { "profile": "lab4", "params": {"q": ["*:*"] } },
      ]
    }
```

__NOTE: The spacing and indentation is important for embedding JSON in YAML correctly__

After running the upgrade, inspect the warming query configmap:
```
k get cm ${LW_K8S_RELEASE}-query-pipeline-warming-queries -o yaml --export
```

The Fusion microservices do not automatically detect changes to a configmap, so you'll need to delete the running query pod(s) to pickup the warming query configmap changes.

In a production environment with only one query pod running, you may want to scale up the deployment (the pod will pick up the configmap changes) before deleting the running pod.

=== Step 4: Deploy the Gatling Simulation to K8s

The `fusion-cloud-native` repo contains a maven project to help customers build query load tests.

You can run that project from an IDE locally but it's better to run the load test from a node closer to your cluster.

Run the gatling simulation Docker image in k8s:

```
kubectl run --generator=run-pod/v1 --restart=Never \
   --image="us.gcr.io/${LW_K8S_GCP_PROJECT}/gatling-qps:lab4" \
   --env="JAVA_OPTS=-Dqps.fusion.url=http://${LW_K8S_GATEWAY_IP}:6764 -Dqps.app=lab4 -Dqps.fusion.pass=password123" \
   gatling-qps -- -s FusionQueryTraffic
```

Be sure to update the password in the run command (look for: `-Dqps.fusion.pass=password123`) to match the admin password you set when first logging into Fusion.

This command creates a pod for the Gatling load test runner; this demonstrates that you don't need Helm to run workloads on Kube, you can just run any arbitrary Docker image as we're doing here.

The `--restart=Never` is so that the test doesn't restart after it completes.

Obviously for a real load test, you probably want to run the load tester outside the cluster, such as on a GCP instance.

=== Step 5: Observe the Query Performance in Grafana

While the load test is running, monitor query performance of the lab4 pipeline and Solr.

Tail the pod logs using:
```
k logs gatling-qps -f
```

=== Step 6: Download the GC log from your Solr pod

Analyze the GC activity of Solr using gceasy.io.

Download the gc log using:
```
k cp ${LW_K8S_RELEASE}-solr-0:/var/solr/logs/solr_gc.log ./solr_gc.log
```
What throughput are you getting? What was the object allocation rate during the load test.






