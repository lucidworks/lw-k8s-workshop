== Lab 4: Monitoring Query Performance

In this lab, you'll load a dataset from Google Cloud Storage and then run a query load test using Gatling.
You'll learn how to monitor query performance using Grafana dashboards.

=== Step 1: Login to Grafana and Import Dashboards

You'll need to get the initial Grafana password from a k8s secret.
See instructions here: https://github.com/lucidworks/fusion-cloud-native#grafana-dashboards

You can expose Grafana to the internet using:
```
kubectl expose deployment ${LW_K8S_RELEASE}-graf-grafana --type=LoadBalancer --name=grafana
```

How do you get the external IP?
```
kubectl get service grafana -o jsonpath='{.status.loadBalancer.ingress[0].ip}'
```

=== Step 2: Add the Load PBL Job and Run It

Create a `lab4` app.

Run `./post_job.sh` from the `lab4` directory to create a PBL job for indexing data from GCS and run it from the Admin UI.

While the job is running, observe the Spark job related pods running in your cluster.

```
k get pods -l jobConfigId=lab4_load_from_GCS -o wide --watch
```

Notice how we're using the Spark Job Config ID `lab4_load_from_GCS` as pod label filter.

While the job is running, open a port-forward to the driver pod port 4040 and navigate to `http://localhost:4040` to view the Spark Job UI.

Ctrl-C once you see the driver pod is `Completed`

Observe which nodes the Spark driver and executor are running on `spark-std-8` ... why is this happening?

=== Step 3: Configure warming queries

Add the following warming queries configuration to your custom values yaml and deploy the change.
```
query-pipeline:
  warmingQueryJson:
    {
      "pipelines": [
        { "pipeline": "lab4", "collection": "lab4", "params": {"q": ["*:*"] } },
        { "pipeline": "lab4", "collection": "lab4", "params": {"q": ["string2_s:cariole^98 text1_txt_en:chemis^57"] } }
      ],
      "profiles": [
        { "profile": "lab4", "params": {"q": ["*:*"] } },
      ]
    }
```

__NOTE: The spacing and indentation is important for embedding JSON in YAML correctly__

After running the upgrade, inspect the warming query configmap:
```
k get cm ${LW_K8S_RELEASE}-query-pipeline-warming-queries -o yaml --export
```

*You'll have to delete the running query pod(s) to pickup the warming query configmap changes.*

=== Step 4: Deploy the Gatling Simulation to K8s

The `fusion-cloud-native` repo contains a maven project to help customers build query load tests.

You can run that project from an IDE locally but it's better to run the load test from a node closer to your cluster.

Run the gatling simulation Docker image in k8s:

```
kubectl run --generator=run-pod/v1 --restart=Never \
   --image="us.gcr.io/${LW_K8S_GCP_PROJECT}/gatling-qps:lab4" \
   --env="JAVA_OPTS=-Dqps.fusion.url=http://${LW_K8S_GATEWAY_IP}:6764 -Dqps.app=lab4" \
   gatling-qps -- -s FusionQueryTraffic
```

This command creates a pod for the Gatling load test runner; no Helm mumbo jumbo needed to run workloads on Kube.

The `--restart=Never` is so that the test doesn't restart after it completes.

Obviously for a real load test, you probably want to run the load tester outside the cluster, such as on a GCP instance.

=== Step 5: Observe the Query Performance in Grafana

While the load test is running, monitor query performance of the lab4 pipeline and Solr.

Tail the pod logs using:
```
k logs gatling-qps -f
```

=== Step 6: Download the GC log for one of your Solr pods

Analyze the GC activity of Solr using gceasy.io.

Download the gc log using:
```
k cp ${LW_K8S_RELEASE}-solr-search-0:/var/solr/logs/solr_gc.log ./solr_gc.log
```
What throughput are you getting? What was the object allocation rate during the load test.






